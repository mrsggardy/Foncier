{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import des librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import time\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import xlsxwriter\n",
    "import numpy as np\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Init divers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_df=list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Init du folder emplacement des fichiers CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath_data = r\"C:\\Users\\gille\\JupyterProjects\\Foncier\\data\\external\"+chr(92)\n",
    "filepath_processed = r\"C:\\Users\\gille\\JupyterProjects\\Foncier\\data\\processed\"+chr(92)\n",
    "filepath_interim = r\"C:\\Users\\gille\\JupyterProjects\\Foncier\\data\\interim\"+chr(92)\n",
    "file_xls_analyse = \"Analyse_dataframe_foncier.xlsx\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fonction Debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def debug(message=\" \") :\n",
    "    ts = time.time()\n",
    "    ts = datetime.datetime.fromtimestamp(ts).strftime('%Y-%m-%d %H:%M:%S')\n",
    "    print (\"{} Debug -> \".format(ts)+str(message))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fonction d'optention du code région via API\n",
    "https://geo.api.gouv.fr/decoupage-administratif/regions#name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_code_region (param) :\n",
    "    URL = 'https://geo.api.gouv.fr/communes?nom={ville}&fields=departement&boost=population&limit=5'.format(ville=param)\n",
    "    reponse = requests.get (URL)\n",
    "    return reponse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{\"nom\":\"Marseille\",\"code\":\"13055\",\"_score\":4.833894444752829,\"departement\":{\"code\":\"13\",\"nom\":\"Bouches-du-Rhône\"}},{\"nom\":\"Marseillette\",\"code\":\"11220\",\"_score\":0.6157962970305906,\"departement\":{\"code\":\"11\",\"nom\":\"Aude\"}},{\"nom\":\"Marseilles-lès-Aubigny\",\"code\":\"18139\",\"_score\":0.4723387123353396,\"departement\":{\"code\":\"18\",\"nom\":\"Cher\"}},{\"nom\":\"Marseille-en-Beauvaisis\",\"code\":\"60387\",\"_score\":0.3013473248598236,\"departement\":{\"code\":\"60\",\"nom\":\"Oise\"}}]\n"
     ]
    }
   ],
   "source": [
    "print (get_code_region('Marseille').text)\n",
    "r = get_code_region('Marseille')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'nom': 'Marseille',\n",
       "  'code': '13055',\n",
       "  '_score': 4.833894444752829,\n",
       "  'departement': {'code': '13', 'nom': 'Bouches-du-Rhône'}},\n",
       " {'nom': 'Marseillette',\n",
       "  'code': '11220',\n",
       "  '_score': 0.6157962970305906,\n",
       "  'departement': {'code': '11', 'nom': 'Aude'}},\n",
       " {'nom': 'Marseilles-lès-Aubigny',\n",
       "  'code': '18139',\n",
       "  '_score': 0.4723387123353396,\n",
       "  'departement': {'code': '18', 'nom': 'Cher'}},\n",
       " {'nom': 'Marseille-en-Beauvaisis',\n",
       "  'code': '60387',\n",
       "  '_score': 0.3013473248598236,\n",
       "  'departement': {'code': '60', 'nom': 'Oise'}}]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fonction de chargement et d'agrégation des fichiers txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_get (filepath) :\n",
    "    \n",
    "    files = [f for f in os.listdir(filepath_data) if f.endswith(\".txt\")]\n",
    "    \n",
    "    for i, file in enumerate(files):\n",
    "        debug(\"Agregation dans le dataframe FONCIER du fichier :\" + file)\n",
    "        list_df.append(pd.read_csv(filepath_data + chr(92) + file, delimiter='|', low_memory=False,\n",
    "                                   decimal=\",\",\n",
    "                                   dtype={\"Surface_Carrez_du_1er_lot\": np.float64,\n",
    "                                         \"Surface_Carrez_du_2eme_lot\": np.float64,\n",
    "                                         \"Surface_Carrez_du_3eme_lot\": np.float64,\n",
    "                                         \"Surface_Carrez_du_4eme_lot\": np.float64,\n",
    "                                         \"Surface_Carrez_du_5eme_lot\": np.float64}\n",
    "                                  ))\n",
    "\n",
    "        debug(\"Nombre de ligne chargées :\" + str(len(list_df[i])))\n",
    "        debug()\n",
    "\n",
    "    debug(\"Fusion des Dataframes\")\n",
    "    df = pd.concat(list_df)\n",
    "    debug()\n",
    "\n",
    "    debug(\"Netoyage des headers de colonne\")\n",
    "    df.rename(columns=lambda x: x.replace(' ', '_').replace('/', '_'), inplace=True)\n",
    "    debug()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fonction d'addition des colonnes et suppression des colonnes additionées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_add_col (df,col_list,col_tot) :\n",
    "    # Certaine colonnes, dont la suppression est demandée maintenant, ont potentiellement déjà été supprimées parce que vide\n",
    "    # Oblige à faire un examen de chaque colonne , 1 par une , et non un drop de la liste complète.\n",
    "    col_to_sum = [col for col in df.columns if col in col_list]\n",
    "    debug (\"Addition des colonnes {c} dans {t}\".format(c=str(col_to_sum),t=col_tot))\n",
    "    df[col_tot]=df[col_to_sum].sum(axis=1)\n",
    "    # debug (\"suppresion des colonnes \"+str(col_to_sum))\n",
    "    # df.drop(col_to_sum,axis=1,inplace=True)\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fonction de suppression des colonnes vides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_del_empty_col (df) :\n",
    "    to_remove = [col for col in df.columns if df[col].value_counts().empty]\n",
    "    debug(\"Supression des colonnes vides :\"+str(to_remove))\n",
    "    df.drop (to_remove,axis=1,inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fonction de génération d'un fichier sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_gen_sample (df,nb_rows,filename,filepath) :\n",
    "    \n",
    "    debug (\"Generation du fichier d'échantillon pour analyse sous excel :\")\n",
    "    debug (filepath+filename)\n",
    "    # Init de l'engine\n",
    "    ts = datetime.datetime.fromtimestamp(time.time()).strftime('%Y-%m-%d_%H_%M_%S')\n",
    "    writer_sample = pd.ExcelWriter(filepath+str(ts)+\"_\"+filename+\".xlsx\", engine='xlsxwriter')\n",
    "\n",
    "    #génération \n",
    "    df.sample(n=nb_rows,random_state=1).to_excel(writer_sample,sheet_name=\"Sample\")\n",
    "\n",
    "    #instanciation de l'onglet \"sample\"\n",
    "    worksheet_sample = writer_sample.sheets['Sample']\n",
    "\n",
    "    #Auto filter des colones\n",
    "    worksheet_sample.autofilter(\"A1:AS\"+str(nb_rows-1))\n",
    "\n",
    "    writer_sample.save()\n",
    "    writer_sample.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generation du fichier d'analyse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_gen_analyse (df,filepath,filename) :\n",
    "    debug(\"Generation du fichier d'analyse\")\n",
    "    path = filepath + filename\n",
    "    writer_analyse = pd.ExcelWriter(path, engine='xlsxwriter')\n",
    "    debug(\"Creation de l'onglet INFO \")\n",
    "    workbook_foncier  = writer_analyse.book\n",
    "    worksheet_info=workbook_foncier.add_worksheet(\"INFO\")\n",
    "    worksheet_drop=workbook_foncier.add_worksheet(\"DROP\")\n",
    "    worksheet_describep=workbook_foncier.add_worksheet(\"DESCRIBE\")\n",
    "    \n",
    "    debug(\"Alimentation de l'onglet INFO \")\n",
    "    cell_format = workbook_foncier.add_format()\n",
    "    cell_format.set_align('vjustify')\n",
    "    buf = io.StringIO()\n",
    "    df.info(buf=buf)\n",
    "    s = buf.getvalue()\n",
    "    worksheet_info.write(0,0,s,cell_format)\n",
    "    \n",
    "    debug(\"Generation des counts par colonne\")\n",
    "    for i,col in enumerate(df.columns):\n",
    "        debug (\"Ajout de la colonne+count au fichier Excel : \"+col)\n",
    "        df[col].value_counts().to_excel(writer_analyse,sheet_name=col)\n",
    "            \n",
    "    writer_analyse.save()\n",
    "    writer_analyse.close()\n",
    "    debug(\"Sauvegarde de l'analyse sous excel\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-11 22:22:46 Debug -> Start\n",
      "2021-05-11 22:22:46 Debug -> ************** Chargement, agrégation, et suppression des colonnes vides\n",
      "2021-05-11 22:22:46 Debug ->  \n",
      "2021-05-11 22:22:46 Debug -> Agregation dans le dataframe FONCIER du fichier :valeursfoncieres-2016.txt\n",
      "2021-05-11 22:23:00 Debug -> Nombre de ligne chargées :2939478\n",
      "2021-05-11 22:23:00 Debug ->  \n",
      "2021-05-11 22:23:00 Debug -> Agregation dans le dataframe FONCIER du fichier :valeursfoncieres-2017.txt\n",
      "2021-05-11 22:23:15 Debug -> Nombre de ligne chargées :3382812\n",
      "2021-05-11 22:23:15 Debug ->  \n",
      "2021-05-11 22:23:15 Debug -> Agregation dans le dataframe FONCIER du fichier :valeursfoncieres-2018.txt\n",
      "2021-05-11 22:23:29 Debug -> Nombre de ligne chargées :3329147\n",
      "2021-05-11 22:23:29 Debug ->  \n",
      "2021-05-11 22:23:29 Debug -> Agregation dans le dataframe FONCIER du fichier :valeursfoncieres-2019.txt\n",
      "2021-05-11 22:23:43 Debug -> Nombre de ligne chargées :3533211\n",
      "2021-05-11 22:23:43 Debug ->  \n",
      "2021-05-11 22:23:43 Debug -> Agregation dans le dataframe FONCIER du fichier :valeursfoncieres-2020.txt\n",
      "2021-05-11 22:23:53 Debug -> Nombre de ligne chargées :2459560\n",
      "2021-05-11 22:23:53 Debug ->  \n",
      "2021-05-11 22:23:53 Debug -> Fusion des Dataframes\n",
      "2021-05-11 22:24:24 Debug ->  \n",
      "2021-05-11 22:24:24 Debug -> Netoyage des headers de colonne\n",
      "2021-05-11 22:24:24 Debug ->  \n",
      "2021-05-11 22:24:24 Debug -> End\n"
     ]
    }
   ],
   "source": [
    "debug (\"Start\")\n",
    "debug (\"************** Chargement, agrégation, et suppression des colonnes vides\")\n",
    "debug ()\n",
    "df_foncier = df_get (filepath_data)\n",
    "debug (\"End\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "debug (\"************** Addition des surfaces Carrez\")\n",
    "\n",
    "df_foncier=df_add_col (df_foncier,[\"Surface_Carrez_du_1er_lot\",\n",
    "                                    \"Surface_Carrez_du_2eme_lot\",\n",
    "                                    \"Surface_Carrez_du_3eme_lot\",\n",
    "                                    \"Surface_Carrez_du_4eme_lot\",\n",
    "                                    \"Surface_Carrez_du_5eme_lot\"],\"Total_surface_carrez\")\n",
    "\n",
    "debug(\"end\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "debug (\"************** Suppression des colonnes inutiles\")\n",
    "\n",
    "to_remove =['No_disposition','No_voie','B_T_Q','Type_de_voie','Voie','Code_postal','Commune','Code_departement','Prefixe_de_section',\n",
    "             'Section','No_plan','No_Volume','1er_lot','2eme_lot','3eme_lot','4eme_lot','5eme_lot','Code_type_local']\n",
    "\n",
    "for col in to_remove :\n",
    "    try :\n",
    "        df_foncier.drop(col,axis=1,inplace=True)\n",
    "    except :\n",
    "        debug (\"Colonne {c} non présente dans le data frame\".format(c=col))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-11 22:26:18 Debug -> ************** Génération du fichier de Sample\n",
      "2021-05-11 22:26:18 Debug -> Generation du fichier d'échantillon pour analyse sous excel :\n",
      "2021-05-11 22:26:18 Debug -> C:\\Users\\gille\\JupyterProjects\\Foncier\\data\\processed\\2021-05-11_22_26_18_Sample Foncier\n",
      "2021-05-11 22:30:59 Debug -> end\n",
      "2021-05-11 22:30:59 Debug ->  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gille\\anaconda3\\lib\\site-packages\\xlsxwriter\\workbook.py:329: UserWarning: Calling close() on already closed file.\n",
      "  warn(\"Calling close() on already closed file.\")\n"
     ]
    }
   ],
   "source": [
    "debug (\"************** Génération du fichier de Sample\")\n",
    "ts = datetime.datetime.fromtimestamp(time.time()).strftime('%Y-%m-%d_%H_%M_%S')\n",
    "df_gen_sample (df_foncier,500000,str(ts)+\"_\"+\"Sample Foncier\",filepath_processed)\n",
    "debug (\"end\")\n",
    "debug ()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sauvegarde du DF au format CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df_foncier.to_csv (filepath_interim+'df_foncier.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
