{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import des librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import time\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import xlsxwriter\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Init divers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Init du folder emplacement des fichiers CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath_data = r\"C:\\Users\\gille\\JupyterProjects\\Foncier\\data\\external\"+chr(92)\n",
    "filepath_processed = r\"C:\\Users\\gille\\JupyterProjects\\Foncier\\data\\processed\"+chr(92)\n",
    "filepath_interim = r\"C:\\Users\\gille\\JupyterProjects\\Foncier\\data\\interim\"+chr(92)\n",
    "file_xls_analyse = \"Analyse_dataframe_foncier.xlsx\"\n",
    "list_df=list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fonction Debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def debug(message=\" \") :\n",
    "    ts = time.time()\n",
    "    ts = datetime.datetime.fromtimestamp(ts).strftime('%Y-%m-%d %H:%M:%S')\n",
    "    print (\"{} Debug -> \".format(ts)+str(message))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fonction de chargement et d'agrégation des fichiers txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_get (filepath) :\n",
    "    \n",
    "    files = [f for f in os.listdir(filepath_data) if f.endswith(\".txt\")]\n",
    "    \n",
    "    for i, file in enumerate(files):\n",
    "        debug(\"Agregation dans le dataframe FONCIER du fichier :\" + file)\n",
    "        list_df.append(pd.read_csv(filepath_data + chr(92) + file, delimiter='|', low_memory=False,\n",
    "                                   decimal=\",\",\n",
    "                                   dtype={\"Surface_Carrez_du_1er_lot\": np.float64,\n",
    "                                         \"Surface_Carrez_du_2eme_lot\": np.float64,\n",
    "                                         \"Surface_Carrez_du_3eme_lot\": np.float64,\n",
    "                                         \"Surface_Carrez_du_4eme_lot\": np.float64,\n",
    "                                         \"Surface_Carrez_du_5eme_lot\": np.float64}\n",
    "                                  ))\n",
    "\n",
    "        debug(\"Nombre de ligne chargées :\" + str(len(list_df[i])))\n",
    "        debug()\n",
    "\n",
    "    debug(\"Fusion des Dataframes\")\n",
    "    df = pd.concat(list_df)\n",
    "    debug()\n",
    "    \n",
    "    col_list = [col for col in df.columns if df[col].dtypes == \"object\"]\n",
    "    debug(\"Mise en majuscule des Objects : \"+str(col_list))\n",
    "    for col in col_list :\n",
    "        df[col]=df[col].str.upper()\n",
    "\n",
    "    debug(\"Netoyage des headers de colonne\")\n",
    "    df.rename(columns=lambda x: x.replace(' ', '_')\n",
    "              .replace('/', '_').replace('é', 'e').replace('è', 'e')\n",
    "              .replace('û', 'u').replace('à', 'a').upper()\n",
    "              , inplace=True)\n",
    "    debug()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fonction d'addition des colonnes et suppression des colonnes additionées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_add_col (df,col_to_sum,col_tot) :\n",
    "    # Certaine colonnes, dont la suppression est demandée maintenant, ont potentiellement déjà été supprimées parce que vide\n",
    "    # Oblige à faire un examen de chaque colonne , 1 par une , et non un drop de la liste complète.\n",
    "    debug (\"Addition des colonnes {c} dans {t}\".format(c=str(col_to_sum),t=col_tot))\n",
    "    df[col_tot]=df[col_to_sum].sum(axis=1)\n",
    "    debug (\"suppresion des colonnes \"+str(col_to_sum).upper())\n",
    "    df.drop(col_to_sum,axis=1,inplace=True)\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fonction de suppression des colonnes vides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_del_empty_col (df) :\n",
    "    to_remove = [col for col in df.columns if df[col].value_counts().empty]\n",
    "    debug(\"Supression des colonnes vides :\"+str(to_remove))\n",
    "    df.drop (to_remove,axis=1,inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fonction de génération d'un fichier sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_gen_sample (df,nb_rows,filename,filepath) :\n",
    "    \n",
    "    debug (\"Generation du fichier d'échantillon pour analyse sous excel :\")\n",
    "    debug (filepath+filename)\n",
    "    # Init de l'engine\n",
    "    ts = datetime.datetime.fromtimestamp(time.time()).strftime('%Y-%m-%d_%H_%M_%S')\n",
    "    writer_sample = pd.ExcelWriter(filepath+str(ts)+\"_\"+filename+\".xlsx\", engine='xlsxwriter')\n",
    "\n",
    "    #génération\n",
    "    df.sample(n=5000000,random_state=1).to_csv (filepath+str(ts)+\"_\"+filename+'.csv')\n",
    "    df.sample(n=nb_rows,random_state=1).to_excel(writer_sample,sheet_name=\"Sample\")\n",
    "\n",
    "    #instanciation de l'onglet \"sample\"\n",
    "    worksheet_sample = writer_sample.sheets['Sample']\n",
    "\n",
    "    #Auto filter des colones\n",
    "    worksheet_sample.autofilter(\"A1:AS\"+str(nb_rows-1))\n",
    "\n",
    "    writer_sample.save()\n",
    "    writer_sample.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generation du fichier d'analyse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_gen_analyse (df,filepath,filename) :\n",
    "    debug(\"Generation du fichier d'analyse\")\n",
    "    path = filepath + filename\n",
    "    writer_analyse = pd.ExcelWriter(path, engine='xlsxwriter')\n",
    "    debug(\"Creation de l'onglet INFO \")\n",
    "    workbook_foncier  = writer_analyse.book\n",
    "    worksheet_info=workbook_foncier.add_worksheet(\"INFO\")\n",
    "    worksheet_drop=workbook_foncier.add_worksheet(\"DROP\")\n",
    "    worksheet_describep=workbook_foncier.add_worksheet(\"DESCRIBE\")\n",
    "    \n",
    "    debug(\"Alimentation de l'onglet INFO \")\n",
    "    cell_format = workbook_foncier.add_format()\n",
    "    cell_format.set_align('vjustify')\n",
    "    buf = io.StringIO()\n",
    "    df.info(buf=buf)\n",
    "    s = buf.getvalue()\n",
    "    worksheet_info.write(0,0,s,cell_format)\n",
    "    \n",
    "    debug(\"Generation des counts par colonne\")\n",
    "    for i,col in enumerate(df.columns):\n",
    "        debug (\"Ajout de la colonne+count au fichier Excel : \"+col)\n",
    "        df[col].value_counts().to_excel(writer_analyse,sheet_name=col)\n",
    "            \n",
    "    writer_analyse.save()\n",
    "    writer_analyse.close()\n",
    "    debug(\"Sauvegarde de l'analyse sous excel\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-13 22:20:17 Debug -> Start\n",
      "2021-05-13 22:20:17 Debug -> ************** Chargement, agrégation, et suppression des colonnes vides\n",
      "2021-05-13 22:20:17 Debug ->  \n",
      "2021-05-13 22:20:17 Debug -> Agregation dans le dataframe FONCIER du fichier :valeursfoncieres-2016_short.txt\n",
      "2021-05-13 22:20:17 Debug -> Nombre de ligne chargées :20\n",
      "2021-05-13 22:20:17 Debug ->  \n",
      "2021-05-13 22:20:17 Debug -> Agregation dans le dataframe FONCIER du fichier :valeursfoncieres-2017_short.txt\n",
      "2021-05-13 22:20:17 Debug -> Nombre de ligne chargées :20\n",
      "2021-05-13 22:20:17 Debug ->  \n",
      "2021-05-13 22:20:17 Debug -> Fusion des Dataframes\n",
      "2021-05-13 22:20:17 Debug ->  \n",
      "2021-05-13 22:20:17 Debug -> Mise en majuscule des Objects : ['Date mutation', 'Nature mutation', 'Type de voie', 'Code voie', 'Voie', 'Commune', 'Section', 'Type local', 'Nature culture']\n",
      "2021-05-13 22:20:17 Debug -> Netoyage des headers de colonne\n",
      "2021-05-13 22:20:17 Debug ->  \n",
      "2021-05-13 22:20:17 Debug -> Supression des colonnes vides :['CODE_SERVICE_CH', 'REFERENCE_DOCUMENT', '1_ARTICLES_CGI', '2_ARTICLES_CGI', '3_ARTICLES_CGI', '4_ARTICLES_CGI', '5_ARTICLES_CGI', 'B_T_Q', 'PREFIXE_DE_SECTION', 'NO_VOLUME', '3EME_LOT', 'SURFACE_CARREZ_DU_3EME_LOT', '4EME_LOT', 'SURFACE_CARREZ_DU_4EME_LOT', '5EME_LOT', 'SURFACE_CARREZ_DU_5EME_LOT', 'IDENTIFIANT_LOCAL', 'NATURE_CULTURE_SPECIALE']\n",
      "2021-05-13 22:20:17 Debug -> End\n"
     ]
    }
   ],
   "source": [
    "debug (\"Start\")\n",
    "debug (\"************** Chargement, agrégation, et suppression des colonnes vides\")\n",
    "debug ()\n",
    "df_foncier = df_del_empty_col(df_get (filepath_data))\n",
    "debug (\"End\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-13 22:20:17 Debug -> ************** Addition des surfaces Carrez\n",
      "2021-05-13 22:20:17 Debug -> Addition des colonnes ['SURFACE_CARREZ_DU_1ER_LOT', 'SURFACE_CARREZ_DU_2EME_LOT', 'SURFACE_CARREZ_DU_3EME_LOT', 'SURFACE_CARREZ_DU_4EME_LOT', 'SURFACE_CARREZ_DU_5EME_LOT'] dans TOTAL_SURF_CARREZ\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"['SURFACE_CARREZ_DU_4EME_LOT', 'SURFACE_CARREZ_DU_5EME_LOT', 'SURFACE_CARREZ_DU_3EME_LOT'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-a298eb90f48b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mdebug\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"************** Addition des surfaces Carrez\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m df_foncier=df_add_col (df_foncier,[\"SURFACE_CARREZ_DU_1ER_LOT\",\n\u001b[0m\u001b[0;32m      4\u001b[0m                                     \u001b[1;34m\"SURFACE_CARREZ_DU_2EME_LOT\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                                     \u001b[1;34m\"SURFACE_CARREZ_DU_3EME_LOT\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-5-3f8d48b77ecc>\u001b[0m in \u001b[0;36mdf_add_col\u001b[1;34m(df, col_to_sum, col_tot)\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;31m# Oblige à faire un examen de chaque colonne , 1 par une , et non un drop de la liste complète.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mdebug\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"Addition des colonnes {c} dans {t}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcol_to_sum\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcol_tot\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcol_tot\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcol_to_sum\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0mdebug\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"suppresion des colonnes \"\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcol_to_sum\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcol_to_sum\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2906\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2907\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2908\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2909\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2910\u001b[0m         \u001b[1;31m# take() does not accept boolean indexers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[1;34m(self, key, axis, raise_missing)\u001b[0m\n\u001b[0;32m   1252\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1253\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1254\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_read_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mraise_missing\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1255\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1256\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[1;34m(self, key, indexer, axis, raise_missing)\u001b[0m\n\u001b[0;32m   1302\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1303\u001b[0m                 \u001b[0mnot_found\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1304\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"{not_found} not in index\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1305\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1306\u001b[0m             \u001b[1;31m# we skip the warning on Categorical\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['SURFACE_CARREZ_DU_4EME_LOT', 'SURFACE_CARREZ_DU_5EME_LOT', 'SURFACE_CARREZ_DU_3EME_LOT'] not in index\""
     ]
    }
   ],
   "source": [
    "debug (\"************** Addition des surfaces Carrez\")\n",
    "\n",
    "df_foncier=df_add_col (df_foncier,[\"SURFACE_CARREZ_DU_1ER_LOT\",\n",
    "                                    \"SURFACE_CARREZ_DU_2EME_LOT\",\n",
    "                                    \"SURFACE_CARREZ_DU_3EME_LOT\",\n",
    "                                    \"SURFACE_CARREZ_DU_4EME_LOT\",\n",
    "                                    \"SURFACE_CARREZ_DU_5EME_LOT\"],\"TOTAL_SURF_CARREZ\")\n",
    "\n",
    "debug(\"end\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "debug (\"************** Suppression des colonnes inutiles\")\n",
    "\n",
    "to_remove =['No_disposition','No_voie','B_T_Q','Type_de_voie','Voie','Code_postal','Commune','Code_departement','Prefixe_de_section',\n",
    "             'Section','No_plan','No_Volume','1er_lot','2eme_lot','3eme_lot','4eme_lot','5eme_lot','Code_type_local']\n",
    "\n",
    "for col in to_remove :\n",
    "    try :\n",
    "        df_foncier.drop(col,axis=1,inplace=True)\n",
    "    except :\n",
    "        debug (\"Colonne {c} non présente dans le data frame\".format(c=col))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "debug (\"************** Génération du fichier de Sample\")\n",
    "df_gen_sample (df_foncier,500000,\"Sample Foncier\",filepath_processed)\n",
    "debug (\"end\")\n",
    "debug ()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sauvegarde du DF au format CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df_foncier.to_csv (filepath_interim+'df_foncier.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_foncier.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
